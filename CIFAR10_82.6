{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPij3h7q/pcHsWxnCtJiPaV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dawsong1011/ML-stuff/blob/main/CIFAR10_82.6\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEE_iq1q3pRZ",
        "outputId": "79c373a1-22d7-466e-f2ca-85c27de719e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/45\n",
            "1562/1562 [==============================] - 52s 30ms/step - loss: 1.6931 - accuracy: 0.3884 - precision_5: 0.5805 - recall_5: 0.1754 - val_loss: 1.5191 - val_accuracy: 0.4501 - val_precision_5: 0.5930 - val_recall_5: 0.3000 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 2/45\n",
            "1562/1562 [==============================] - 46s 29ms/step - loss: 1.2975 - accuracy: 0.5408 - precision_5: 0.7218 - recall_5: 0.3527 - val_loss: 1.0877 - val_accuracy: 0.6167 - val_precision_5: 0.7382 - val_recall_5: 0.5182 - lr: 0.0010\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 3/45\n",
            "1562/1562 [==============================] - 46s 30ms/step - loss: 1.1292 - accuracy: 0.6070 - precision_5: 0.7613 - recall_5: 0.4493 - val_loss: 0.9923 - val_accuracy: 0.6518 - val_precision_5: 0.7646 - val_recall_5: 0.5397 - lr: 0.0010\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 4/45\n",
            "1562/1562 [==============================] - 49s 31ms/step - loss: 1.0295 - accuracy: 0.6451 - precision_5: 0.7804 - recall_5: 0.5114 - val_loss: 1.1398 - val_accuracy: 0.6268 - val_precision_5: 0.6914 - val_recall_5: 0.5632 - lr: 0.0010\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 5/45\n",
            "1562/1562 [==============================] - 47s 30ms/step - loss: 0.9673 - accuracy: 0.6694 - precision_5: 0.7922 - recall_5: 0.5458 - val_loss: 1.1183 - val_accuracy: 0.6401 - val_precision_5: 0.7233 - val_recall_5: 0.5740 - lr: 0.0010\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 6/45\n",
            "1562/1562 [==============================] - 48s 31ms/step - loss: 0.9087 - accuracy: 0.6883 - precision_5: 0.8024 - recall_5: 0.5766 - val_loss: 0.9248 - val_accuracy: 0.6943 - val_precision_5: 0.7663 - val_recall_5: 0.6300 - lr: 0.0010\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 7/45\n",
            "1562/1562 [==============================] - 47s 30ms/step - loss: 0.8754 - accuracy: 0.7020 - precision_5: 0.8082 - recall_5: 0.5986 - val_loss: 0.8338 - val_accuracy: 0.7234 - val_precision_5: 0.7877 - val_recall_5: 0.6659 - lr: 0.0010\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 8/45\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.8396 - accuracy: 0.7167 - precision_5: 0.8146 - recall_5: 0.6186 - val_loss: 0.8306 - val_accuracy: 0.7329 - val_precision_5: 0.8056 - val_recall_5: 0.6721 - lr: 0.0010\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 9/45\n",
            "1562/1562 [==============================] - 46s 29ms/step - loss: 0.8058 - accuracy: 0.7264 - precision_5: 0.8216 - recall_5: 0.6352 - val_loss: 0.7929 - val_accuracy: 0.7412 - val_precision_5: 0.8093 - val_recall_5: 0.6873 - lr: 0.0010\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 10/45\n",
            "1562/1562 [==============================] - 46s 30ms/step - loss: 0.7776 - accuracy: 0.7369 - precision_5: 0.8284 - recall_5: 0.6494 - val_loss: 0.7241 - val_accuracy: 0.7472 - val_precision_5: 0.8126 - val_recall_5: 0.6919 - lr: 0.0010\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 11/45\n",
            "1562/1562 [==============================] - 47s 30ms/step - loss: 0.7557 - accuracy: 0.7454 - precision_5: 0.8327 - recall_5: 0.6613 - val_loss: 0.7846 - val_accuracy: 0.7414 - val_precision_5: 0.8034 - val_recall_5: 0.6901 - lr: 0.0010\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 12/45\n",
            "1562/1562 [==============================] - 47s 30ms/step - loss: 0.7374 - accuracy: 0.7545 - precision_5: 0.8379 - recall_5: 0.6702 - val_loss: 0.8424 - val_accuracy: 0.7324 - val_precision_5: 0.8026 - val_recall_5: 0.6832 - lr: 0.0010\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 13/45\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.7243 - accuracy: 0.7585 - precision_5: 0.8405 - recall_5: 0.6804 - val_loss: 0.6362 - val_accuracy: 0.7907 - val_precision_5: 0.8410 - val_recall_5: 0.7462 - lr: 0.0010\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 14/45\n",
            "1562/1562 [==============================] - 47s 30ms/step - loss: 0.7078 - accuracy: 0.7618 - precision_5: 0.8421 - recall_5: 0.6873 - val_loss: 0.6687 - val_accuracy: 0.7767 - val_precision_5: 0.8267 - val_recall_5: 0.7300 - lr: 0.0010\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 15/45\n",
            "1562/1562 [==============================] - 46s 29ms/step - loss: 0.6907 - accuracy: 0.7682 - precision_5: 0.8477 - recall_5: 0.6933 - val_loss: 0.7277 - val_accuracy: 0.7692 - val_precision_5: 0.8204 - val_recall_5: 0.7294 - lr: 0.0010\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 16/45\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.6813 - accuracy: 0.7728 - precision_5: 0.8490 - recall_5: 0.7007 - val_loss: 0.6128 - val_accuracy: 0.7970 - val_precision_5: 0.8444 - val_recall_5: 0.7571 - lr: 0.0010\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 17/45\n",
            "1562/1562 [==============================] - 46s 30ms/step - loss: 0.6721 - accuracy: 0.7772 - precision_5: 0.8523 - recall_5: 0.7064 - val_loss: 0.5782 - val_accuracy: 0.8027 - val_precision_5: 0.8569 - val_recall_5: 0.7562 - lr: 0.0010\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 18/45\n",
            "1562/1562 [==============================] - 46s 30ms/step - loss: 0.6649 - accuracy: 0.7753 - precision_5: 0.8516 - recall_5: 0.7064 - val_loss: 0.5749 - val_accuracy: 0.8084 - val_precision_5: 0.8608 - val_recall_5: 0.7617 - lr: 0.0010\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 19/45\n",
            "1562/1562 [==============================] - 48s 31ms/step - loss: 0.6530 - accuracy: 0.7791 - precision_5: 0.8530 - recall_5: 0.7130 - val_loss: 0.6454 - val_accuracy: 0.7893 - val_precision_5: 0.8368 - val_recall_5: 0.7533 - lr: 0.0010\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 20/45\n",
            "1562/1562 [==============================] - 47s 30ms/step - loss: 0.6399 - accuracy: 0.7851 - precision_5: 0.8566 - recall_5: 0.7181 - val_loss: 0.5834 - val_accuracy: 0.8026 - val_precision_5: 0.8477 - val_recall_5: 0.7623 - lr: 0.0010\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 21/45\n",
            "1562/1562 [==============================] - 47s 30ms/step - loss: 0.6334 - accuracy: 0.7887 - precision_5: 0.8577 - recall_5: 0.7234 - val_loss: 0.5403 - val_accuracy: 0.8180 - val_precision_5: 0.8593 - val_recall_5: 0.7783 - lr: 0.0010\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 22/45\n",
            "1562/1562 [==============================] - 47s 30ms/step - loss: 0.6261 - accuracy: 0.7909 - precision_5: 0.8592 - recall_5: 0.7271 - val_loss: 0.5510 - val_accuracy: 0.8150 - val_precision_5: 0.8559 - val_recall_5: 0.7802 - lr: 0.0010\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 23/45\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.6169 - accuracy: 0.7927 - precision_5: 0.8608 - recall_5: 0.7311 - val_loss: 0.5246 - val_accuracy: 0.8262 - val_precision_5: 0.8659 - val_recall_5: 0.7877 - lr: 0.0010\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 24/45\n",
            "1562/1562 [==============================] - 47s 30ms/step - loss: 0.6112 - accuracy: 0.7953 - precision_5: 0.8636 - recall_5: 0.7324 - val_loss: 0.6138 - val_accuracy: 0.7987 - val_precision_5: 0.8405 - val_recall_5: 0.7654 - lr: 0.0010\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 25/45\n",
            "1562/1562 [==============================] - 46s 29ms/step - loss: 0.6073 - accuracy: 0.7987 - precision_5: 0.8638 - recall_5: 0.7360 - val_loss: 0.5291 - val_accuracy: 0.8245 - val_precision_5: 0.8689 - val_recall_5: 0.7874 - lr: 0.0010\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 26/45\n",
            "1562/1562 [==============================] - 46s 30ms/step - loss: 0.6031 - accuracy: 0.7995 - precision_5: 0.8631 - recall_5: 0.7397 - val_loss: 0.6375 - val_accuracy: 0.7907 - val_precision_5: 0.8316 - val_recall_5: 0.7559 - lr: 0.0010\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 27/45\n",
            "1562/1562 [==============================] - 48s 31ms/step - loss: 0.5943 - accuracy: 0.8029 - precision_5: 0.8649 - recall_5: 0.7445 - val_loss: 0.5567 - val_accuracy: 0.8165 - val_precision_5: 0.8600 - val_recall_5: 0.7836 - lr: 0.0010\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 28/45\n",
            "1562/1562 [============================>.] - ETA: 0s - loss: 0.5922 - accuracy: 0.8030 - precision_5: 0.8652 - recall_5: 0.7444Restoring model weights from the end of the best epoch: 23.\n",
            "1562/1562 [==============================] - 46s 29ms/step - loss: 0.5922 - accuracy: 0.8029 - precision_5: 0.8652 - recall_5: 0.7444 - val_loss: 0.6062 - val_accuracy: 0.8043 - val_precision_5: 0.8497 - val_recall_5: 0.7680 - lr: 0.0010\n",
            "Epoch 28: early stopping\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.5246 - accuracy: 0.8262 - precision_5: 0.8659 - recall_5: 0.7877\n",
            "Test accuracy: 0.826200008392334\n",
            "Test precision: 0.865889847278595\n",
            "Test recall: 0.7876999974250793\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten,Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "# Loading the dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Preprocessing the data\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "datagen.fit(train_images)\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.1\n",
        "    decay_step = 30\n",
        "    if epoch % decay_step == 0 and epoch:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
        "\n",
        "\n",
        "callbacks = [LearningRateScheduler(lr_scheduler, verbose=1),early_stopping]\n",
        "\n",
        "# Building the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Conv2D(32, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.225),\n",
        "\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(.2),\n",
        "\n",
        "    Conv2D(32, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Conv2D(32, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(.175),\n",
        "\n",
        "    Conv2D(128, (3, 3), padding='same'),  # New layer\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.3),  # Adjusted dropout\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
        "\n",
        "# Train the model with data augmentation\n",
        "model.fit(datagen.flow(train_images, train_labels, batch_size=32),\n",
        "          steps_per_epoch=len(train_images) / 32, epochs=45,\n",
        "          validation_data=(test_images, test_labels),\n",
        "          callbacks=callbacks)\n",
        "\n",
        "# Evaluating the model\n",
        "\n",
        "test_loss, test_acc, test_precision, test_recall  = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Test precision:', test_precision)\n",
        "print('Test recall:', test_recall)"
      ]
    }
  ]
}